{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hHB-VDn5Wkp1"
      },
      "source": [
        "# Group 7 Project\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qxRjXAa4Lmqs"
      },
      "source": [
        "import sqlite3\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from wordcloud import WordCloud, STOPWORDS\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "\n",
        "import string\n",
        "import re\n",
        "\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import PorterStemmer\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.layers import Dense , LSTM , Embedding\n",
        "from keras.models import Sequential\n",
        "from keras.callbacks import EarlyStopping\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "import pickle"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b9sEdp-sL9la"
      },
      "source": [
        "# using the SQLite Table to read data.\n",
        "con = sqlite3.connect('/content/drive/MyDrive/ai/database (1).sqlite') "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dH30z0dyMVjw"
      },
      "source": [
        "filtered_data = pd.read_sql_query(\"\"\" SELECT * FROM Reviews WHERE Score != 3 LIMIT 5000\"\"\", con)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZxIFp7rAMy_t"
      },
      "source": [
        "# Give reviews with Score>3 a positive rating, and reviews with a score<3 a negative rating.\n",
        "def partition(x):\n",
        "    if x < 3:\n",
        "        return 'negative'\n",
        "    return 'positive'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 716
        },
        "id": "uVblqLTBM1bW",
        "outputId": "55b7e0da-83ec-4d59-b0e2-59c2506ecb88"
      },
      "source": [
        "#changing reviews with score less than 3 to be positive and vice-versa\n",
        "actualScore = filtered_data['Score']\n",
        "positiveNegative = actualScore.map(partition) \n",
        "filtered_data['Score'] = positiveNegative\n",
        "print(\"Number of data points in our data\", filtered_data.shape)\n",
        "filtered_data.head(10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of data points in our data (5000, 10)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Id</th>\n",
              "      <th>ProductId</th>\n",
              "      <th>UserId</th>\n",
              "      <th>ProfileName</th>\n",
              "      <th>HelpfulnessNumerator</th>\n",
              "      <th>HelpfulnessDenominator</th>\n",
              "      <th>Score</th>\n",
              "      <th>Time</th>\n",
              "      <th>Summary</th>\n",
              "      <th>Text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>B001E4KFG0</td>\n",
              "      <td>A3SGXH7AUHU8GW</td>\n",
              "      <td>delmartian</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>positive</td>\n",
              "      <td>1303862400</td>\n",
              "      <td>Good Quality Dog Food</td>\n",
              "      <td>I have bought several of the Vitality canned d...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>B00813GRG4</td>\n",
              "      <td>A1D87F6ZCVE5NK</td>\n",
              "      <td>dll pa</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>negative</td>\n",
              "      <td>1346976000</td>\n",
              "      <td>Not as Advertised</td>\n",
              "      <td>Product arrived labeled as Jumbo Salted Peanut...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>B000LQOCH0</td>\n",
              "      <td>ABXLMWJIXXAIN</td>\n",
              "      <td>Natalia Corres \"Natalia Corres\"</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>positive</td>\n",
              "      <td>1219017600</td>\n",
              "      <td>\"Delight\" says it all</td>\n",
              "      <td>This is a confection that has been around a fe...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>B000UA0QIQ</td>\n",
              "      <td>A395BORC6FGVXV</td>\n",
              "      <td>Karl</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>negative</td>\n",
              "      <td>1307923200</td>\n",
              "      <td>Cough Medicine</td>\n",
              "      <td>If you are looking for the secret ingredient i...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>B006K2ZZ7K</td>\n",
              "      <td>A1UQRSCLF8GW1T</td>\n",
              "      <td>Michael D. Bigham \"M. Wassir\"</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>positive</td>\n",
              "      <td>1350777600</td>\n",
              "      <td>Great taffy</td>\n",
              "      <td>Great taffy at a great price.  There was a wid...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>6</td>\n",
              "      <td>B006K2ZZ7K</td>\n",
              "      <td>ADT0SRK1MGOEU</td>\n",
              "      <td>Twoapennything</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>positive</td>\n",
              "      <td>1342051200</td>\n",
              "      <td>Nice Taffy</td>\n",
              "      <td>I got a wild hair for taffy and ordered this f...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>7</td>\n",
              "      <td>B006K2ZZ7K</td>\n",
              "      <td>A1SP2KVKFXXRU1</td>\n",
              "      <td>David C. Sullivan</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>positive</td>\n",
              "      <td>1340150400</td>\n",
              "      <td>Great!  Just as good as the expensive brands!</td>\n",
              "      <td>This saltwater taffy had great flavors and was...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>8</td>\n",
              "      <td>B006K2ZZ7K</td>\n",
              "      <td>A3JRGQVEQN31IQ</td>\n",
              "      <td>Pamela G. Williams</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>positive</td>\n",
              "      <td>1336003200</td>\n",
              "      <td>Wonderful, tasty taffy</td>\n",
              "      <td>This taffy is so good.  It is very soft and ch...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>9</td>\n",
              "      <td>B000E7L2R4</td>\n",
              "      <td>A1MZYO9TZK0BBI</td>\n",
              "      <td>R. James</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>positive</td>\n",
              "      <td>1322006400</td>\n",
              "      <td>Yay Barley</td>\n",
              "      <td>Right now I'm mostly just sprouting this so my...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>10</td>\n",
              "      <td>B00171APVA</td>\n",
              "      <td>A21BT40VZCCYT4</td>\n",
              "      <td>Carol A. Reed</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>positive</td>\n",
              "      <td>1351209600</td>\n",
              "      <td>Healthy Dog Food</td>\n",
              "      <td>This is a very healthy dog food. Good for thei...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Id  ...                                               Text\n",
              "0   1  ...  I have bought several of the Vitality canned d...\n",
              "1   2  ...  Product arrived labeled as Jumbo Salted Peanut...\n",
              "2   3  ...  This is a confection that has been around a fe...\n",
              "3   4  ...  If you are looking for the secret ingredient i...\n",
              "4   5  ...  Great taffy at a great price.  There was a wid...\n",
              "5   6  ...  I got a wild hair for taffy and ordered this f...\n",
              "6   7  ...  This saltwater taffy had great flavors and was...\n",
              "7   8  ...  This taffy is so good.  It is very soft and ch...\n",
              "8   9  ...  Right now I'm mostly just sprouting this so my...\n",
              "9  10  ...  This is a very healthy dog food. Good for thei...\n",
              "\n",
              "[10 rows x 10 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IC3pN_RMT3Uf"
      },
      "source": [
        "# Data Deduplication"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fNCEZlQ9T8cM"
      },
      "source": [
        "#Sorting data according to ProductId in ascending order\n",
        "sorted_data=filtered_data.sort_values('ProductId', axis=0, ascending=True, inplace=False, kind='quicksort', na_position='last')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0QVEI7uRT-x5",
        "outputId": "544872d6-56c7-4cb3-ab8f-8190fc5ba850"
      },
      "source": [
        "#Deduplication of entries\n",
        "final=sorted_data.drop_duplicates(subset={\"UserId\",\"ProfileName\",\"Time\",\"Text\"}, keep='first', inplace=False)\n",
        "final.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4986, 10)"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rG7Kw58JUCM1",
        "outputId": "39843c36-71fa-4e34-a9b5-166ac16f1e6b"
      },
      "source": [
        "#Checking to see how much % of data still remains\n",
        "(final['Id'].size*1.0)/(filtered_data['Id'].size*1.0)*100"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "99.72"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ErSeFzefCNlf"
      },
      "source": [
        "# Text Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "obJTj_0kCR9d",
        "outputId": "caa940e6-d96a-4082-c773-bbb7837fef26"
      },
      "source": [
        "nltk.download('stopwords')\n",
        "stop=set(stopwords.words('english'))\n",
        "sno=nltk.SnowballStemmer('english')\n",
        "def cleanhtml(s):\n",
        "  a=re.sub('[|>.*?|\\.*|?.*?]',\"\",s)\n",
        "  return a\n",
        "def cleanpunc(s):\n",
        "  a=re.sub('[.|,|!,|)|(|/|\\|”|\\’|#|@|$|-|%|]',\"\",s)\n",
        "  return a"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6YZwM0nnCexk"
      },
      "source": [
        "i=0;\n",
        "str1=''\n",
        "final_string=[]\n",
        "pos_words=[]\n",
        "neg_words=[]\n",
        "s=''\n",
        "for s in final['Text'].values:\n",
        "    f=[]\n",
        "    s=cleanhtml(s)\n",
        "    for w in s.split():\n",
        "        for c in cleanpunc(w).split():\n",
        "            if((c.isalpha())&(len(c)>2)):\n",
        "                if(c.lower()not in stop):\n",
        "                    s=(sno.stem(c.lower())).encode('utf8')\n",
        "                    f.append(s)\n",
        "                    if(final['Score'].values)[i]=='positive':\n",
        "                        pos_words.append(s)\n",
        "                    if(final['Score'].values)[i]=='negative':\n",
        "                        neg_words.append(s)\n",
        "                else:\n",
        "                    continue\n",
        "            else:\n",
        "                continue\n",
        "    str1=b\" \".join(f)\n",
        "    final_string.append(str1)\n",
        "    i=i+1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "krRb0M1MDzlZ"
      },
      "source": [
        "#Adding cleaned text in final dataframe\n",
        "final['CleanedText']=final_string\n",
        "conn=sqlite3.connect('final.sqlite')\n",
        "c=conn.cursor()\n",
        "conn.text_factory=str\n",
        "final.to_sql('Reviews',conn,schema=None,if_exists='replace')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "hl0EpJLxD_Vj",
        "outputId": "55a288ac-ff20-48af-f501-2960d3d62a0e"
      },
      "source": [
        "final.head(3)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Id</th>\n",
              "      <th>ProductId</th>\n",
              "      <th>UserId</th>\n",
              "      <th>ProfileName</th>\n",
              "      <th>HelpfulnessNumerator</th>\n",
              "      <th>HelpfulnessDenominator</th>\n",
              "      <th>Score</th>\n",
              "      <th>Time</th>\n",
              "      <th>Summary</th>\n",
              "      <th>Text</th>\n",
              "      <th>CleanedText</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2546</th>\n",
              "      <td>2774</td>\n",
              "      <td>B00002NCJC</td>\n",
              "      <td>A196AJHU9EASJN</td>\n",
              "      <td>Alex Chaffee</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>positive</td>\n",
              "      <td>1282953600</td>\n",
              "      <td>thirty bucks?</td>\n",
              "      <td>Why is this $[...] when the same product is av...</td>\n",
              "      <td>b'product avail victor trap unreal cours total...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2547</th>\n",
              "      <td>2775</td>\n",
              "      <td>B00002NCJC</td>\n",
              "      <td>A13RRPGE79XFFH</td>\n",
              "      <td>reader48</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>positive</td>\n",
              "      <td>1281052800</td>\n",
              "      <td>Flies Begone</td>\n",
              "      <td>We have used the Victor fly bait for 3 seasons...</td>\n",
              "      <td>b'use victor fli bait season beat great product'</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1145</th>\n",
              "      <td>1244</td>\n",
              "      <td>B00002Z754</td>\n",
              "      <td>A3B8RCEI0FXFI6</td>\n",
              "      <td>B G Chase</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>positive</td>\n",
              "      <td>962236800</td>\n",
              "      <td>WOW Make your own 'slickers' !</td>\n",
              "      <td>I just received my shipment and could hardly w...</td>\n",
              "      <td>b'receiv shipment could hard wait tri product ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        Id  ...                                        CleanedText\n",
              "2546  2774  ...  b'product avail victor trap unreal cours total...\n",
              "2547  2775  ...   b'use victor fli bait season beat great product'\n",
              "1145  1244  ...  b'receiv shipment could hard wait tri product ...\n",
              "\n",
              "[3 rows x 11 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5BDqcI2eWoMb"
      },
      "source": [
        "# Test- Train Split"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2gAVrmhPWrj4",
        "outputId": "ed0722ab-6928-4a5f-8bb3-28929d07a653"
      },
      "source": [
        "!pip install sklearn\n",
        "from sklearn.model_selection import train_test_split\n",
        "X = final['CleanedText']\n",
        "y = final['Score']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    \n",
        "    X, y, test_size=0.20, random_state=1, stratify=y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: sklearn in /usr/local/lib/python3.7/dist-packages (0.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from sklearn) (0.22.2.post1)\n",
            "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sklearn) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sklearn) (1.19.5)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sklearn) (1.0.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m9HDO16pX9Ka",
        "outputId": "4490cc2e-cebc-4953-9583-f7bd257e6f09"
      },
      "source": [
        "X_train.shape, X_test.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((3988,), (998,))"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IAxybox_M-2d",
        "outputId": "e713f7a0-b8ad-44d5-c97c-0ee0e7cf2e3e"
      },
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "labelEncoder = LabelEncoder()\n",
        "\n",
        "y_train = labelEncoder.fit_transform(y_train)\n",
        "y_test = labelEncoder.transform(y_test)\n",
        "\n",
        "labels = labelEncoder.classes_.tolist()\n",
        "print(labels) # index-> class"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['negative', 'positive']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VSwDKyf7LoQM"
      },
      "source": [
        "# Bag Of Words"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yknhlh2yLtbJ"
      },
      "source": [
        "bow_vectorizer = CountVectorizer(max_features=10000)\n",
        "bow_vectorizer.fit(X_train)\n",
        "\n",
        "# transform\n",
        "bow_X_train = bow_vectorizer.transform(X_train)\n",
        "bow_X_test = bow_vectorizer.transform(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gv5tKIJEYMZV"
      },
      "source": [
        "# Logistic Regression with BoW"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k-a4dXtrYbl6"
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SWDENbKlZSRY"
      },
      "source": [
        "def train_and_eval(model, trainX, trainY, testX, testY):\n",
        "\n",
        "    # training\n",
        "    _ = model.fit(trainX, trainY)\n",
        "\n",
        "    # predictions\n",
        "    y_preds_train = model.predict(trainX)\n",
        "    y_preds_test = model.predict(testX)\n",
        "\n",
        "    # evaluation\n",
        "    print()\n",
        "    print(model)\n",
        "    print(f\"Train accuracy score : {accuracy_score(y_train, y_preds_train)}\")\n",
        "    print(f\"Test accuracy score : {accuracy_score(y_test, y_preds_test)}\")\n",
        "    print('\\n',40*'-')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yaNbjpgXYOzE",
        "outputId": "741a25dc-015e-49c8-e469-df5a117ab3ad"
      },
      "source": [
        "C = [0.001, 0.01, 0.1, 1, 10]\n",
        "\n",
        "for c in C: \n",
        "    # Define model\n",
        "    log_model = LogisticRegression(C=c, max_iter=500, random_state=1)\n",
        "    \n",
        "    # Train and evaluate model\n",
        "    train_and_eval(model=log_model,\n",
        "                   trainX=bow_X_train,\n",
        "                   trainY=y_train,\n",
        "                   testX=bow_X_test,\n",
        "                   testY=y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "LogisticRegression(C=0.001, class_weight=None, dual=False, fit_intercept=True,\n",
            "                   intercept_scaling=1, l1_ratio=None, max_iter=500,\n",
            "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
            "                   random_state=1, solver='lbfgs', tol=0.0001, verbose=0,\n",
            "                   warm_start=False)\n",
            "Train accuracy score : 0.8385155466399198\n",
            "Test accuracy score : 0.8376753507014028\n",
            "\n",
            " ----------------------------------------\n",
            "\n",
            "LogisticRegression(C=0.01, class_weight=None, dual=False, fit_intercept=True,\n",
            "                   intercept_scaling=1, l1_ratio=None, max_iter=500,\n",
            "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
            "                   random_state=1, solver='lbfgs', tol=0.0001, verbose=0,\n",
            "                   warm_start=False)\n",
            "Train accuracy score : 0.8600802407221665\n",
            "Test accuracy score : 0.8517034068136272\n",
            "\n",
            " ----------------------------------------\n",
            "\n",
            "LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,\n",
            "                   intercept_scaling=1, l1_ratio=None, max_iter=500,\n",
            "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
            "                   random_state=1, solver='lbfgs', tol=0.0001, verbose=0,\n",
            "                   warm_start=False)\n",
            "Train accuracy score : 0.9380641925777332\n",
            "Test accuracy score : 0.8917835671342685\n",
            "\n",
            " ----------------------------------------\n",
            "\n",
            "LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
            "                   intercept_scaling=1, l1_ratio=None, max_iter=500,\n",
            "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
            "                   random_state=1, solver='lbfgs', tol=0.0001, verbose=0,\n",
            "                   warm_start=False)\n",
            "Train accuracy score : 0.9914744232698094\n",
            "Test accuracy score : 0.8907815631262525\n",
            "\n",
            " ----------------------------------------\n",
            "\n",
            "LogisticRegression(C=10, class_weight=None, dual=False, fit_intercept=True,\n",
            "                   intercept_scaling=1, l1_ratio=None, max_iter=500,\n",
            "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
            "                   random_state=1, solver='lbfgs', tol=0.0001, verbose=0,\n",
            "                   warm_start=False)\n",
            "Train accuracy score : 0.9997492477432297\n",
            "Test accuracy score : 0.8777555110220441\n",
            "\n",
            " ----------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lbFoGchva858"
      },
      "source": [
        "# Tf-Idf"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7w7gbaQta_Rj"
      },
      "source": [
        "tfidf_vectorizer = TfidfVectorizer(max_features=10000)\n",
        "tfidf_vectorizer.fit(X_train)\n",
        "\n",
        "# transform\n",
        "tfidf_X_train = tfidf_vectorizer.transform(X_train)\n",
        "tfidf_X_test = tfidf_vectorizer.transform(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "euprPC2dbU3-"
      },
      "source": [
        "# Logistic Regression with Tf-Idf"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tqps_7CkbUNY",
        "outputId": "cb86aed7-224c-4059-e704-e0dd6f54377c"
      },
      "source": [
        "# Hyperparameters\n",
        "C = [0.001, 0.01, 0.1, 1, 10]\n",
        "\n",
        "for c in C: \n",
        "    # Define model\n",
        "    log_model = LogisticRegression(C=c, max_iter=500, random_state=1)\n",
        "    \n",
        "    # Train and evaluate model\n",
        "    train_and_eval(model=log_model,\n",
        "                   trainX=tfidf_X_train,\n",
        "                   trainY=y_train,\n",
        "                   testX=tfidf_X_test,\n",
        "                   testY=y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "LogisticRegression(C=0.001, class_weight=None, dual=False, fit_intercept=True,\n",
            "                   intercept_scaling=1, l1_ratio=None, max_iter=500,\n",
            "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
            "                   random_state=1, solver='lbfgs', tol=0.0001, verbose=0,\n",
            "                   warm_start=False)\n",
            "Train accuracy score : 0.8380140421263791\n",
            "Test accuracy score : 0.8376753507014028\n",
            "\n",
            " ----------------------------------------\n",
            "\n",
            "LogisticRegression(C=0.01, class_weight=None, dual=False, fit_intercept=True,\n",
            "                   intercept_scaling=1, l1_ratio=None, max_iter=500,\n",
            "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
            "                   random_state=1, solver='lbfgs', tol=0.0001, verbose=0,\n",
            "                   warm_start=False)\n",
            "Train accuracy score : 0.8380140421263791\n",
            "Test accuracy score : 0.8376753507014028\n",
            "\n",
            " ----------------------------------------\n",
            "\n",
            "LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,\n",
            "                   intercept_scaling=1, l1_ratio=None, max_iter=500,\n",
            "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
            "                   random_state=1, solver='lbfgs', tol=0.0001, verbose=0,\n",
            "                   warm_start=False)\n",
            "Train accuracy score : 0.8380140421263791\n",
            "Test accuracy score : 0.8376753507014028\n",
            "\n",
            " ----------------------------------------\n",
            "\n",
            "LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
            "                   intercept_scaling=1, l1_ratio=None, max_iter=500,\n",
            "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
            "                   random_state=1, solver='lbfgs', tol=0.0001, verbose=0,\n",
            "                   warm_start=False)\n",
            "Train accuracy score : 0.8884152457372116\n",
            "Test accuracy score : 0.8787575150300602\n",
            "\n",
            " ----------------------------------------\n",
            "\n",
            "LogisticRegression(C=10, class_weight=None, dual=False, fit_intercept=True,\n",
            "                   intercept_scaling=1, l1_ratio=None, max_iter=500,\n",
            "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
            "                   random_state=1, solver='lbfgs', tol=0.0001, verbose=0,\n",
            "                   warm_start=False)\n",
            "Train accuracy score : 0.9884653961885657\n",
            "Test accuracy score : 0.8957915831663327\n",
            "\n",
            " ----------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OGOTwGGibmLD"
      },
      "source": [
        "def plot_cm(y_true, y_pred):\n",
        "    plt.figure(figsize=(6,6))\n",
        "    \n",
        "    cm = confusion_matrix(y_true, y_pred, normalize='true')\n",
        "    \n",
        "    sns.heatmap(\n",
        "        cm, annot=True, cmap='Blues', cbar=False, fmt='.2f',\n",
        "        xticklabels=labels, yticklabels=labels)\n",
        "    \n",
        "    return plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OwC5RhjMbpCO",
        "outputId": "6a13920e-4c31-4bc1-d8de-91ca3aa419c6"
      },
      "source": [
        "bmodel = LogisticRegression(C=1, max_iter=500, random_state=1)\n",
        "bmodel.fit(tfidf_X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
              "                   intercept_scaling=1, l1_ratio=None, max_iter=500,\n",
              "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
              "                   random_state=1, solver='lbfgs', tol=0.0001, verbose=0,\n",
              "                   warm_start=False)"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C9ajmfYkbvuF"
      },
      "source": [
        "# predictions\n",
        "y_preds_train = bmodel.predict(tfidf_X_train)\n",
        "y_preds_test = bmodel.predict(tfidf_X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HB0kWX4VbymO",
        "outputId": "19759010-a794-4c45-fe0a-466bc3806355"
      },
      "source": [
        "print(f\"Train accuracy score : {accuracy_score(y_train, y_preds_train)}\")\n",
        "print(f\"Test accuracy score : {accuracy_score(y_test, y_preds_test)}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train accuracy score : 0.8884152457372116\n",
            "Test accuracy score : 0.8787575150300602\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oO62huynSGyI"
      },
      "source": [
        "# Naives- Bayes Classifier with BOW"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "843zt9jYSLTT",
        "outputId": "6ebb7e38-967f-4489-dbe2-43239a366112"
      },
      "source": [
        "alphas = [0, 0.2, 0.6, 0.8, 1]\n",
        "\n",
        "for a  in alphas: \n",
        "    # Define model\n",
        "    nb_model = MultinomialNB(alpha=a)\n",
        "\n",
        "    # Train and evaluate model\n",
        "    train_and_eval(model=nb_model,\n",
        "                   trainX=bow_X_train,\n",
        "                   trainY=y_train,\n",
        "                   testX=bow_X_test,\n",
        "                   testY=y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "MultinomialNB(alpha=0, class_prior=None, fit_prior=True)\n",
            "Train accuracy score : 0.9771815446339017\n",
            "Test accuracy score : 0.8657314629258517\n",
            "\n",
            " ----------------------------------------\n",
            "\n",
            "MultinomialNB(alpha=0.2, class_prior=None, fit_prior=True)\n",
            "Train accuracy score : 0.9646439317953862\n",
            "Test accuracy score : 0.8877755511022044\n",
            "\n",
            " ----------------------------------------\n",
            "\n",
            "MultinomialNB(alpha=0.6, class_prior=None, fit_prior=True)\n",
            "Train accuracy score : 0.9523570712136409\n",
            "Test accuracy score : 0.8817635270541082\n",
            "\n",
            " ----------------------------------------\n",
            "\n",
            "MultinomialNB(alpha=0.8, class_prior=None, fit_prior=True)\n",
            "Train accuracy score : 0.9485957873620863\n",
            "Test accuracy score : 0.875751503006012\n",
            "\n",
            " ----------------------------------------\n",
            "\n",
            "MultinomialNB(alpha=1, class_prior=None, fit_prior=True)\n",
            "Train accuracy score : 0.9418254764292878\n",
            "Test accuracy score : 0.8767535070140281\n",
            "\n",
            " ----------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6_v7O54RSSc4"
      },
      "source": [
        "# Naive Bayes classifier with Tf-Idf"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hXNVkgNpSUoE",
        "outputId": "1eeb060a-c57e-4f45-a3cc-badfdbe3f3b7"
      },
      "source": [
        "alphas = [0, 0.2, 0.6, 0.8, 1]\n",
        "\n",
        "for a  in alphas: \n",
        "    # Define model\n",
        "    nb_model = MultinomialNB(alpha=a)\n",
        "\n",
        "    # Train and evaluate model\n",
        "    train_and_eval(model=nb_model,\n",
        "                   trainX=tfidf_X_train,\n",
        "                   trainY=y_train,\n",
        "                   testX=tfidf_X_test,\n",
        "                   testY=y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "MultinomialNB(alpha=0, class_prior=None, fit_prior=True)\n",
            "Train accuracy score : 0.966900702106319\n",
            "Test accuracy score : 0.8587174348697395\n",
            "\n",
            " ----------------------------------------\n",
            "\n",
            "MultinomialNB(alpha=0.2, class_prior=None, fit_prior=True)\n",
            "Train accuracy score : 0.9069709127382146\n",
            "Test accuracy score : 0.8557114228456913\n",
            "\n",
            " ----------------------------------------\n",
            "\n",
            "MultinomialNB(alpha=0.6, class_prior=None, fit_prior=True)\n",
            "Train accuracy score : 0.8505516549648947\n",
            "Test accuracy score : 0.8386773547094188\n",
            "\n",
            " ----------------------------------------\n",
            "\n",
            "MultinomialNB(alpha=0.8, class_prior=None, fit_prior=True)\n",
            "Train accuracy score : 0.843530591775326\n",
            "Test accuracy score : 0.8376753507014028\n",
            "\n",
            " ----------------------------------------\n",
            "\n",
            "MultinomialNB(alpha=1, class_prior=None, fit_prior=True)\n",
            "Train accuracy score : 0.8405215646940822\n",
            "Test accuracy score : 0.8376753507014028\n",
            "\n",
            " ----------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ewv2wtdob9VM"
      },
      "source": [
        "# Deployment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9gMBX8yZcBag"
      },
      "source": [
        "with open(\"transformer.pkl\", \"wb\") as f:\n",
        "    pickle.dump(tfidf_vectorizer, f)\n",
        "    \n",
        "with open(\"model.pkl\", \"wb\") as f:\n",
        "    pickle.dump(bmodel, f)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZYQKS2aHcEQ6"
      },
      "source": [
        "from sklearn import preprocessing\n",
        "def get_sentiment(review):\n",
        "    # preprocessing\n",
        "    x = cleanhtml(review)\n",
        "    x=cleanpunc(x)\n",
        "    #vectorization\n",
        "    x = tfidf_vectorizer.transform([x])\n",
        "    #prediction\n",
        "    y = int(bmodel.predict(x.reshape(1,-1)))\n",
        "    return labels[y]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LXXaM3cbWCbx"
      },
      "source": [
        "# Predictions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FFhvl2ZlcHoM",
        "outputId": "a6400608-33b4-4ac8-9a86-bb76657ea0ee"
      },
      "source": [
        "# positive review\n",
        "review = \"This product is great, I love it\"\n",
        "print(f\"This is a {get_sentiment(review)} review!\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "This is a positive review!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pbDFboQkVwA3",
        "outputId": "2ec782f7-2d15-4325-f08a-dc23e9e1369f"
      },
      "source": [
        "# negative review\n",
        "review = \"This product is bad, its not worth it\"\n",
        "print(f\"This is a {get_sentiment(review)} review!\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "This is a negative review!\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}